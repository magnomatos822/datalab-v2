# ğŸ—ï¸ Medallion Architecture + Snowflake ACID Implementation

## ğŸ“Š VisÃ£o Geral da Arquitetura

Este projeto implementa uma **Medallion Architecture** robusta integrada com **Snowflake** para garantir propriedades **ACID** em todas as transformaÃ§Ãµes de dados.

### ğŸ¯ Objetivos

- âœ… **SeparaÃ§Ã£o clara de responsabilidades** por camadas (Bronze, Silver, Gold)
- âœ… **Garantias ACID** atravÃ©s do Snowflake para transaÃ§Ãµes crÃ­ticas
- âœ… **Qualidade de dados** com validaÃ§Ãµes automatizadas
- âœ… **Auditoria completa** de lineage e transformaÃ§Ãµes
- âœ… **Escalabilidade** horizontal e vertical
- âœ… **Observabilidade** com mÃ©tricas e alertas

## ğŸ›ï¸ Camadas da Arquitetura

### ğŸ¥‰ **BRONZE LAYER - Raw Data**
- **PropÃ³sito**: IngestÃ£o de dados brutos sem transformaÃ§Ã£o
- **CaracterÃ­sticas**:
  - Preserva formato original dos dados
  - Auditoria completa de origem
  - DetecÃ§Ã£o de duplicatas
  - Versionamento para rastreabilidade

**Buckets MinIO:**
```
bronze-raw-data/       # Dados brutos de sistemas externos
bronze-streaming/      # Dados de streaming em tempo real  
bronze-batch/         # ExtraÃ§Ãµes em lote
bronze-external/      # Fontes externas (APIs, FTP, etc.)
```

### ğŸ¥ˆ **SILVER LAYER - Cleaned Data**
- **PropÃ³sito**: Dados limpos, validados e normalizados
- **CaracterÃ­sticas**:
  - Limpeza e validaÃ§Ã£o de dados
  - DeduplicaÃ§Ã£o inteligente
  - NormalizaÃ§Ã£o de formatos
  - AplicaÃ§Ã£o de regras de negÃ³cio bÃ¡sicas
  - **TransaÃ§Ãµes ACID** via Snowflake

**Buckets MinIO:**
```
silver-cleaned/       # Dados limpos e validados
silver-validated/     # Dados com regras de negÃ³cio aplicadas
silver-normalized/    # Dados normalizados e padronizados
```

### ğŸ¥‡ **GOLD LAYER - Business Ready**
- **PropÃ³sito**: Dados agregados e prontos para consumo
- **CaracterÃ­sticas**:
  - AgregaÃ§Ãµes de negÃ³cio
  - MÃ©tricas calculadas
  - DimensÃµes e fatos
  - OtimizaÃ§Ãµes para consulta
  - **Garantias ACID** para consistÃªncia

**Buckets MinIO:**
```
gold-analytics/       # Dados para analytics e BI
gold-reporting/       # Datasets para relatÃ³rios
gold-ml-features/     # Features para Machine Learning
```

## ğŸ”„ Propriedades ACID com Snowflake

### **Atomicity (Atomicidade)**
- Todas as transformaÃ§Ãµes DBT sÃ£o executadas em transaÃ§Ãµes
- Rollback automÃ¡tico em caso de falha
- OperaÃ§Ãµes all-or-nothing

### **Consistency (ConsistÃªncia)**
- ValidaÃ§Ãµes de schema automÃ¡ticas
- Testes de qualidade obrigatÃ³rios
- Regras de negÃ³cio enforÃ§adas

### **Isolation (Isolamento)**
- TransaÃ§Ãµes concorrentes isoladas
- PrevenÃ§Ã£o de dirty reads
- Versionamento de dados

### **Durability (Durabilidade)**
- PersistÃªncia garantida no Snowflake
- Backup automÃ¡tico
- RecuperaÃ§Ã£o point-in-time

## ğŸ› ï¸ Stack TecnolÃ³gica

### **Armazenamento**
- **MinIO**: Data Lake com buckets organizados por camada
- **PostgreSQL**: Metadados e catÃ¡logo
- **Snowflake**: Data Warehouse com garantias ACID

### **Processamento**
- **Apache Spark**: Processamento distribuÃ­do
- **dbt**: TransformaÃ§Ãµes SQL com controle de qualidade
- **Apache Hop**: ETL visual e workflows

### **OrquestraÃ§Ã£o**
- **Prefect**: OrquestraÃ§Ã£o de workflows
- **Nessie**: Versionamento de dados

### **MLOps**
- **MLflow**: Gerenciamento de modelos
- **Feature Store**: Features organizadas por domÃ­nio

## ğŸ“ Estrutura de Buckets (Medalha)

```
ğŸ“¦ MinIO Buckets
â”œâ”€â”€ ğŸ¥‰ BRONZE (Raw Data)
â”‚   â”œâ”€â”€ bronze-raw-data/
â”‚   â”‚   â”œâ”€â”€ year=2025/month=08/day=14/
â”‚   â”‚   â”œâ”€â”€ domain=finance/
â”‚   â”‚   â”œâ”€â”€ domain=sales/
â”‚   â”‚   â””â”€â”€ domain=operations/
â”‚   â”œâ”€â”€ bronze-streaming/
â”‚   â”œâ”€â”€ bronze-batch/
â”‚   â””â”€â”€ bronze-external/
â”‚
â”œâ”€â”€ ğŸ¥ˆ SILVER (Cleaned Data)  
â”‚   â”œâ”€â”€ silver-cleaned/
â”‚   â”œâ”€â”€ silver-validated/
â”‚   â””â”€â”€ silver-normalized/
â”‚
â”œâ”€â”€ ğŸ¥‡ GOLD (Business Ready)
â”‚   â”œâ”€â”€ gold-analytics/
â”‚   â”œâ”€â”€ gold-reporting/
â”‚   â””â”€â”€ gold-ml-features/
â”‚
â””â”€â”€ ğŸ”§ OPERATIONAL
    â”œâ”€â”€ mlflow-artifacts/
    â”œâ”€â”€ feature-store/
    â”œâ”€â”€ backup-metadata/
    â””â”€â”€ dev-sandbox/
```

## ğŸƒ Como Executar

### 1ï¸âƒ£ **Inicializar Infraestrutura**
```bash
# Subir todos os serviÃ§os
docker compose up -d --build

# Verificar status
docker compose ps
```

### 2ï¸âƒ£ **Configurar Snowflake** (Opcional para desenvolvimento)
```bash
# Para desenvolvimento, usar PostgreSQL como fallback
export DBT_TARGET=postgres_local

# Para produÃ§Ã£o com Snowflake real
export SNOWFLAKE_ACCOUNT=your-account.snowflakecomputing.com
export SNOWFLAKE_USER=your-user
export SNOWFLAKE_PASSWORD=your-password
export DBT_TARGET=snowflake_prod
```

### 3ï¸âƒ£ **Executar Pipeline DBT**
```bash
# Dentro do container Spark
docker exec -it spark_master bash

# Instalar dependÃªncias dbt
pip install dbt-snowflake dbt-postgres dbt-spark

# Executar transformaÃ§Ãµes
cd /opt/bitnami/spark/dbt_project
dbt deps
dbt run --target snowflake_dev

# Executar testes de qualidade
dbt test

# Gerar documentaÃ§Ã£o
dbt docs generate
dbt docs serve
```

## ğŸ“Š Monitoramento e Qualidade

### **MÃ©tricas AutomÃ¡ticas**
- âœ… Volume de dados por camada
- âœ… Scores de qualidade
- âœ… Tempo de processamento
- âœ… Taxa de sucesso/falha
- âœ… DetecÃ§Ã£o de anomalias

### **Alertas Configurados**
- ğŸš¨ Queda de qualidade > 20%
- ğŸš¨ Falhas em transformaÃ§Ãµes crÃ­ticas
- ğŸš¨ Lacunas temporais nos dados
- ğŸš¨ ViolaÃ§Ãµes de schema

### **Dashboards DisponÃ­veis**
- ğŸ“ˆ **Data Quality Dashboard**: MÃ©tricas de qualidade por camada
- ğŸ“Š **Operational Dashboard**: Performance e SLAs
- ğŸ” **Data Lineage**: Rastreamento de origem a destino

## ğŸ” SeguranÃ§a e Compliance

### **Controle de Acesso**
- Bronze: Acesso restrito para ingestÃ£o
- Silver: Leitura para processamento
- Gold: Consumo por aplicaÃ§Ãµes

### **Auditoria**
- Log completo de todas as operaÃ§Ãµes
- Rastreamento de lineage automÃ¡tico
- Versionamento de schemas

### **Compliance**
- RetenÃ§Ã£o de dados configurÃ¡vel por camada
- AnonymizaÃ§Ã£o automÃ¡tica
- Backup e recovery point-in-time

## ğŸš€ PrÃ³ximos Passos

1. **Implementar Streaming**: Kafka + Spark Streaming para dados real-time
2. **ML Automation**: AutoML pipelines integrados
3. **Data Mesh**: FederaÃ§Ã£o de domÃ­nios de dados
4. **Advanced Analytics**: Graph analytics e time series
5. **Multi-Cloud**: ReplicaÃ§Ã£o entre provedores

## ğŸ“ Contato e Suporte

- **Data Engineering Team**: data-engineering@company.com
- **Documentation**: [Confluence Link]
- **Slack Channel**: #datalab-medallion
- **On-Call**: PagerDuty rotation

---

**ğŸ¯ Esta arquitetura garante alta qualidade, confiabilidade e escalabilidade para todos os dados da organizaÃ§Ã£o, seguindo as melhores prÃ¡ticas da indÃºstria.**
